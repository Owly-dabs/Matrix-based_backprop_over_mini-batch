{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "038f7da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "09076ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mnist_loader\n",
    "import network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c9e7b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return 1.0/(1.0 + np.exp(-z))\n",
    "\n",
    "def sigmoid_prime(z):\n",
    "    return sigmoid(z)*(1-sigmoid(z))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f74078e4",
   "metadata": {},
   "source": [
    "## Training using the normal network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5923b674",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 8960/10000\n",
      "Epoch 1: 9187/10000\n",
      "Epoch 2: 9272/10000\n",
      "Epoch 3: 9282/10000\n",
      "Epoch 4: 9338/10000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "training_data, validation_data, test_data = mnist_loader.load_data_wrapper()\n",
    "net = network.Network([784,30,10])\n",
    "net.SGD(training_data,5,16,3.0,test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edc7fd89",
   "metadata": {},
   "source": [
    "## Feedforward with network_matx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c4ba5555",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "training_data, validation_data, test_data = mnist_loader.load_data_wrapper()\n",
    "# Create Net\n",
    "net = network.Network([784,30,10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fc3d7185",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: 3,784,1 | Y shape: 3,10,1\n"
     ]
    }
   ],
   "source": [
    "training_data = list(training_data)\n",
    "n = len(training_data)\n",
    "if test_data:\n",
    "    test_data = list(test_data)\n",
    "    n_test = len(test_data)\n",
    "\n",
    "# Create mini-batch\n",
    "random.shuffle(training_data)\n",
    "mini_batch = training_data[0:3]\n",
    "X = [x for x,y in mini_batch]\n",
    "Y = [y for x,y in mini_batch]\n",
    "print(\"X shape: {},{},{} | Y shape: {},{},{}\".format(len(X),len(X[0]),len(X[0][0]),len(Y),len(Y[0]),len(Y[0][0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "980c7189",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weights shape: (30x784),(10x30) | biases shape: (30x1),(10x1)\n"
     ]
    }
   ],
   "source": [
    "# Initiate\n",
    "nabla_b = [np.zeros(b.shape) for b in net.biases]\n",
    "nabla_w = [np.zeros(w.shape) for w in net.weights]\n",
    "#TODO: print nabla shapes\n",
    "print(\"weights shape: ({}x{}),({}x{}) | biases shape: ({}x{}),({}x{})\".format(len(nabla_w[0]),len(nabla_w[0][0]),len(nabla_w[1]),len(nabla_w[1][0]),len(nabla_b[0]),len(nabla_b[0][0]),len(nabla_b[1]),len(nabla_b[1][0])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "420a3391",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of activation: (3, 30, 1)\n",
      "Shape of activation: (3, 10, 1)\n"
     ]
    }
   ],
   "source": [
    "# feedforward\n",
    "activation = X # shape = (mini_batch_size, 784, 1) \n",
    "activations = [X] # list to store all activations, layer-by-layer\n",
    "Zs = [] # list to store all z vectors, layer-by-layer\n",
    "for b,w in zip(net.biases,net.weights):\n",
    "    Z = np.transpose(np.dot(w, activation),(1,0,2)) + b\n",
    "    Zs.append(Z)\n",
    "    activation = sigmoid(Z)\n",
    "    activations.append(activation)\n",
    "    print(\"Shape of activation: {}\".format(activation.shape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5207e213",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of nabla_b: ((10, 1))\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2c2099af",
   "metadata": {},
   "source": [
    "## Figuring out the dimensions to get the weight vector\n",
    "Don't run the cells below!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e47e3451",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1, 10, 3), (1, 3, 30), (1, 10, 1, 30), (10, 30))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Figuring out the dimensions to get the weight vector\n",
    "dum1 = np.transpose(delta,(2,1,0))\n",
    "dum2 = np.transpose(activations[-2],(2,0,1))\n",
    "prod = np.dot(dum1, dum2)\n",
    "#nabla_w[-1] = np.dot(delta, activations[-2])\n",
    "dum1.shape,dum2.shape,prod.shape,np.squeeze(prod).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aa1a442d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10, 3), (3, 30), (1, 10, 1, 30))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check if the above code sums the 16 examples correctly\n",
    "_dum1 = np.squeeze(np.transpose(delta,(2,1,0)))\n",
    "_dum2 = np.squeeze(np.transpose(activations[-2],(2,0,1)))\n",
    "_prod = np.dot(dum1, dum2)\n",
    "_dum1.shape, _dum2.shape,_prod.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73c76d39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Delta: (10, 1)\n",
      "Shape of nabla_w: (10, 30)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(3, 1, 30)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Finding an easier way --> sum delta first (WRONG ACTUALLY)\n",
    "delta = np.sum(net.cost_derivative(activations[-1],Y) * \\\n",
    "        sigmoid_prime(Zs[-1]),axis=0)\n",
    "print(\"Shape of Delta: {}\".format(delta.shape))\n",
    "\n",
    "nabla_b[-1] = delta\n",
    "nabla_w[-1] = np.dot(delta, np.sum(np.transpose(activations[-2],(0,2,1)),axis=0))\n",
    "print(\"Shape of nabla_w: {}\".format(nabla_w[-1].shape))\n",
    "np.transpose(activations[-2],(0,2,1)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5ce042c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300, 0)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(prod == _prod),np.sum(prod == nabla_w[-1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dab8963",
   "metadata": {},
   "source": [
    "As you can observe above, using `np.sum` on `delta` above does not get the same matrix as using `np.sum` after the dot product in `nabla_w`. Imagine trying to multiply delta and activation as shown below:\n",
    "\n",
    "delta --> Vector A (10x3): [\n",
    "    [A0_1, A0_2, A0_3], \n",
    "    [A1_1, A1_2, A1_3], \n",
    "    [A2_1, A2_2, A2_3], \n",
    "            ...\n",
    "    [A9_1, A9_2, A9_3]       \n",
    "]\n",
    "\n",
    "activation (30x3): [\n",
    "    [B0_1, B0_2, B0_3],\n",
    "    [B1_1, B1_2, B1_3],\n",
    "    [B2_1, B2_2, B2_3],\n",
    "            ...\n",
    "    [B29_1, B29_2, B29_3]       \n",
    "]\n",
    "\n",
    "activation_transposed --> Vector B (3x30): [\n",
    "    [B0_1, B1_1, B2_1 ... B29_1],\n",
    "    [B0_2, B1_2, B2_2 ... B29_2],\n",
    "    [B0_3, B1_3, B2_3 ... B29_3]\n",
    "]\n",
    "\n",
    "The desired dot product is shown (10x30): [\n",
    "    [(A0_1*B0_1 + A0_2*B0_2 + A0_3*B0_3), (A0_1*B1_1 + A0_2*B1_2 + A0_3*B1_3) ... (A0_1*B29_1 + A0_2*B29_2 + A0_3*B29_3)],\n",
    "    [(A1_1*B0_1 + A1_2*B0_2 + A1_3*B0_3), (A1_1*B1_1 + A1_2*B1_2 + A1_3*B1_3) ... (A1_1*B29_1 + A1_2*B29_2 + A1_3*B29_3),\n",
    "                                                        ... ...\n",
    "    [(A9_1*B0_1 + A9_2*B0_2 + A9_3*B0_3), (A9_1*B1_1 + A9_2*B1_2 + A9_3*B1_3) ... (A9_1*B29_1 + A9_2*B29_2 + A9_3*B29_3),\n",
    "] \n",
    "\n",
    "if delta is summed before the dot product, the dot product will be as follows: [\n",
    "    [(A0_1 + A0_2 + A0_3)(B0_1 + B0_2 + B0_3), (A0_1 + A0_2 + A0_3)(B1_1 + B1_2 + B1_3) ... (A0_1 + A0_2 + A0_3)(B29_1 + B29_2 + B29_3)],\n",
    "    [(A1_1 + A1_2 + A1_3)(B0_1 + B0_2 + B0_3), (A1_1 + A1_2 + A1_3)(B1_1 + B1_2 + B1_3) ... (A1_1 + A1_2 + A1_3)(B29_1 + B29_2 + B29_3)],\n",
    "                                                        ... ...\n",
    "    [(A9_1 + A9_2 + A9_3)(B0_1 + B0_2 + B0_3), (A9_1 + A9_2 + A9_3)(B1_1 + B1_2 + B1_3) ... (A9_1 + A9_2 + A9_3)(B29_1 + B29_2 + B29_3)]\n",
    "]\n",
    "\n",
    "Thus, the sum of the `nabla_w` must only be taken after the dot product."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91181193",
   "metadata": {},
   "source": [
    "## Backward Pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7fbfd9ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last layer\n",
      "Shape of delta_batch: (3, 10, 1)\n",
      "Shape of nabla_b: (10, 1)\n",
      "Shape of nabla_w: (10, 30)\n",
      "2nd last layer\n",
      "Shape of delta_batch: (3, 30, 1)\n",
      "Shape of nabla_b: (30, 1)\n",
      "Shape of nabla_w: (30, 784)\n"
     ]
    }
   ],
   "source": [
    "# Correct backward pass\n",
    "print(\"Last layer\")\n",
    "delta_batch = net.cost_derivative(activations[-1],Y) * \\\n",
    "        sigmoid_prime(Zs[-1]) # shape = (mini_batch_size,10,1)\n",
    "print(\"Shape of delta_batch: {}\".format(delta_batch.shape))\n",
    "nabla_b[-1] = np.sum(delta_batch, axis=0)\n",
    "print(\"Shape of nabla_b: {}\".format(nabla_b[-1].shape))\n",
    "nabla_w[-1] = np.squeeze(np.dot(np.transpose(delta_batch,(2,1,0)),np.transpose(activations[-2],(2,0,1))))\n",
    "print(\"Shape of nabla_w: {}\".format(nabla_w[-1].shape))\n",
    "\n",
    "# Subsequent backward pass\n",
    "print(\"2nd last layer\")\n",
    "Z = Zs[-2]\n",
    "sp = sigmoid_prime(Z)\n",
    "\n",
    "delta_batch = np.transpose(np.dot(net.weights[-2+1].transpose(), delta_batch),(1,0,2)) * sp\n",
    "print(\"Shape of delta_batch: {}\".format(delta_batch.shape))\n",
    "nabla_b[-2] = np.sum(delta_batch,axis=0)\n",
    "print(\"Shape of nabla_b: {}\".format(nabla_b[-2].shape))\n",
    "nabla_w[-2] = np.squeeze(np.dot(np.transpose(delta_batch,(2,1,0)), np.transpose(activations[-2-1],(2,0,1))))\n",
    "print(\"Shape of nabla_w: {}\".format(nabla_w[-2].shape))\n",
    "#net.weights[-1].shape,delta_batch.shape,sp.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce3306c9",
   "metadata": {},
   "source": [
    "## The Final Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3425f7a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import mnist_loader\n",
    "import network_matx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0e38254e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "training_data, validation_data, test_data = mnist_loader.load_data_wrapper()\n",
    "# Create Net\n",
    "net = network_matx.Network([784,30,10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "072fd290",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 8172/10000\n",
      "Epoch 1: 8310/10000\n",
      "Epoch 2: 8420/10000\n",
      "Epoch 3: 9328/10000\n",
      "Epoch 4: 9363/10000\n"
     ]
    }
   ],
   "source": [
    "net.SGD(training_data,5,16,3.0,test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ee20433",
   "metadata": {},
   "source": [
    "## The Comparison Time Test\n",
    "Yay it works! Now to see if the matrix-based approach has actually made the network faster..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3222b1ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import mnist_loader\n",
    "import network\n",
    "import network_matx\n",
    "import time\n",
    "\n",
    "COUNT = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6736564",
   "metadata": {},
   "source": [
    "Without the matrix-based approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f6b605ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 8971/10000\n",
      "Epoch 1: 9151/10000\n",
      "Epoch 2: 9220/10000\n",
      "Epoch 3: 9301/10000\n",
      "Epoch 4: 9321/10000\n",
      "Epoch 0: 8169/10000\n",
      "Epoch 1: 8347/10000\n",
      "Epoch 2: 8381/10000\n",
      "Epoch 3: 8444/10000\n",
      "Epoch 4: 8497/10000\n",
      "Epoch 0: 9013/10000\n",
      "Epoch 1: 9159/10000\n",
      "Epoch 2: 9225/10000\n",
      "Epoch 3: 9272/10000\n",
      "Epoch 4: 9330/10000\n",
      "Time taken for 5 epochs of SGD w/o matrix: 12.1394\n"
     ]
    }
   ],
   "source": [
    "time_diff = []\n",
    "for i in range(COUNT):\n",
    "    # Load data\n",
    "    training_data, validation_data, test_data = mnist_loader.load_data_wrapper()\n",
    "    # Create Net\n",
    "    net = network.Network([784,30,10])\n",
    "    tic = time.perf_counter()\n",
    "    net.SGD(training_data,5,16,3.0,test_data)\n",
    "    toc = time.perf_counter()\n",
    "    time_diff.append(toc-tic)\n",
    "    print(toc-tic)\n",
    "\n",
    "print(\"Time taken for 5 epochs of SGD w/o matrix: {:0.4f}\".format(np.average(time_diff)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce75be58",
   "metadata": {},
   "source": [
    "With Matrix-based approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1806fb9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 8976/10000\n",
      "Epoch 1: 9152/10000\n",
      "Epoch 2: 9240/10000\n",
      "Epoch 3: 9254/10000\n",
      "Epoch 4: 9311/10000\n",
      "8.865893532998598\n",
      "Epoch 0: 8886/10000\n",
      "Epoch 1: 9156/10000\n",
      "Epoch 2: 9233/10000\n",
      "Epoch 3: 9331/10000\n",
      "Epoch 4: 9395/10000\n",
      "8.823941388000094\n",
      "Epoch 0: 7124/10000\n",
      "Epoch 1: 7259/10000\n",
      "Epoch 2: 7328/10000\n",
      "Epoch 3: 9250/10000\n",
      "Epoch 4: 9309/10000\n",
      "8.894066030999966\n",
      "Time taken for 5 epochs of SGD w/ matrix: 8.8613\n"
     ]
    }
   ],
   "source": [
    "time_diff = []\n",
    "for i in range(COUNT):\n",
    "    # Load data\n",
    "    training_data, validation_data, test_data = mnist_loader.load_data_wrapper()\n",
    "    # Create Net\n",
    "    net = network_matx.Network([784,30,10])\n",
    "    tic = time.perf_counter()\n",
    "    net.SGD(training_data,5,16,3.0,test_data)\n",
    "    toc = time.perf_counter()\n",
    "    time_diff.append(toc-tic)\n",
    "    print(toc-tic)\n",
    "print(\"Time taken for 5 epochs of SGD w/ matrix: {:0.4f}\".format(np.average(time_diff)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d94d9b2b",
   "metadata": {},
   "source": [
    "As shown above, for 5 epochs, SGD, using the matrix-based approach for each mini-batch, is 12.1394 - 8.8613 = 3.2781, which is approximately a 27% decrease in time taken. This is a significant increase in speed for SGD.\n",
    "\n",
    "The following test will use different number of epochs to observe the  change in difference in time taken between the network w/o matrix based approach against the network w/ matrix based approach"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d226679",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.5.6 ('nndl')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "086e577c4aca0c45e997c8fdeec73970cb17575425cc715a661514961b8a486b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
